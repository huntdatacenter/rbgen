
//          Copyright Gavin Band 2008 - 2012.
// Distributed under the Boost Software License, Version 1.0.
//    (See accompanying file LICENSE_1_0.txt or copy at
//          http://www.boost.org/LICENSE_1_0.txt)

#include <string>
#include <fstream>
#include <vector>
#include <algorithm>
#include <functional>
#include <boost/filesystem.hpp>
#include <boost/format.hpp>
#include <boost/tuple/tuple.hpp>
#include <boost/optional.hpp>
#include "appcontext/CmdLineOptionProcessor.hpp"
#include "appcontext/ApplicationContext.hpp"
#include "appcontext/get_current_time_as_string.hpp"
#include "genfile/bgen/bgen.hpp"
#include "genfile/zlib.hpp"
#include "db/Connection.hpp"
#include "db/SQLStatement.hpp"
#include "../../bgen_revision_autogenerated.hpp"

namespace bfs = boost::filesystem ;

// #define DEBUG 1

namespace globals {
	std::string const program_name = "bgenix" ;
	std::string const program_version = bgen_revision ;
}

struct IndexBgenOptionProcessor: public appcontext::CmdLineOptionProcessor
{
public:
	std::string get_program_name() const { return globals::program_name ; }

	void declare_options( appcontext::OptionProcessor& options ) {
		// Meta-options
		options.set_help_option( "-help" ) ;

		options.declare_group( "Input / output file options" ) ;
		options[ "-g" ]
			.set_description(
				"Path of bgen file to operate on.  (An optional form where \"-g\" is omitted and the filename is specified as the first argument, i.e. bgenix <filename>, can also be used)."
			)
			.set_takes_single_value()
			.set_takes_value_by_position(1)
			.set_is_required()
		;

		options[ "-table" ]
			.set_description( "Specify the table (or view) that bgenix should read the file index from."
				"This only affects reading the index file.  The named table or view should have the"
				" same schema as the Variant table written by bgenix on index creation."
			)
			.set_takes_single_value()
			.set_default_value( "Variant" )
		;
		
		options.declare_group( "Indexing options" ) ;
		options[ "-index" ]
			.set_description( "Specify that bgenix should build an index for the BGEN file"
				" specified by the -g option."
			)
		;
		options[ "-clobber" ]
			.set_description(
				"Specify that bgenix should overwrite existing index file if it exists."
			)
		;

		options.declare_group( "Variant selection options" ) ;
		options[ "-incl-range" ]
			.set_description(
				"Include variants in the specified genomic interval in the output. "
				"(If the argument is the name of a valid readable file, the file will "
				"be opened and whitespace-separated rsids read from it instead.)"
				" Each interval must be of the form <chr>:<pos1>-<pos2> where <chr> is a chromosome identifier "
				" and pos1 and pos2 are positions with pos2 >= pos1. "
				" One of pos1 and pos2 can also be omitted, in which case the range extends to the start or"
				" end of the chromosome as appropriate. "
				" Position ranges are treated as closed (i.e. <pos1> and <pos2> are included in the range)."
				"If this is specified multiple times, variants in any of the specified ranges will be included."
			)
			.set_takes_value_by_position(2)
			.set_takes_values_until_next_option()
		;

		options[ "-excl-range" ]
			.set_description(
				"Exclude variants in the specified genomic interval from the output. "
				"See the description of -incl-range for details."
				"If this is specified multiple times, variants in any of the specified ranges will be excluded."
			)
			.set_takes_values_until_next_option()
		;

		options[ "-incl-rsids" ]
			.set_description(
				"Include variants with the specified rsid(s) in the output. "
				"If the argument is the name of a valid readable file, the file will "
				"be opened and whitespace-separated rsids read from it instead."
				"If this is specified multiple times, variants with any of the specified ids will be included."
			)
			.set_takes_values_until_next_option()
		;

		options[ "-excl-rsids" ]
			.set_description(
				"Exclude variants with the specified rsid(s) from the output. "
				"See the description of -incl-range for details."
					"If this is specified multiple times, variants with any of the specified ids will be excluded."
			)
			.set_takes_values_until_next_option()
		;
		
		options.declare_group( "Output options" ) ;
		options[ "-list" ]
			.set_description( "Suppress BGEN output; instead output a list of variants." ) ;
		options[ "-v11" ]
			.set_description(
				"Output BGEN v1.1 format.  (Currently, this is only supported if the input"
				" is in BGEN v1.2 format with 8 bits per probability, all samples are diploid,"
				" and all variants biallelic)."
			) ;
		options[ "-vcf" ]
			.set_description(
				"Output vcf format instead of vcf format."
			) ;
		options[ "-with-rowid" ]
			.set_description( "Create an index file without using the 'WITHOUT ROWID' tables.  These are suitable for use with sqlite versions < 3.8.2" ) ;

		// Option interdependencies
		options.option_excludes_group( "-index", "Variant selection options" ) ;
		options.option_excludes_group( "-index", "Output options" ) ;
		options.option_excludes_option( "-list", "-v11" ) ;
		options.option_excludes_option( "-vcf", "-list" ) ;
		options.option_excludes_option( "-vcf", "-v11" ) ;
		options.option_implies_option( "-clobber", "-index" ) ;
	}
} ;

typedef uint8_t byte_t ;

// 
struct FileMetadata {
	FileMetadata():
		size(0)
	{}

	FileMetadata( FileMetadata const& other ):
		filename( other.filename ),
		size( other.size ),
		last_write_time( other.last_write_time ),
		first_bytes( other.first_bytes )
	{}

	FileMetadata& operator=( FileMetadata const& other ) {
		filename = other.filename ;
		size = other.size ;
		last_write_time = other.last_write_time ;
		first_bytes = other.first_bytes ;
		return *this ;
	}
	
	std::string filename ;
	int64_t size ;
	std::time_t last_write_time ;
	std::vector< byte_t > first_bytes ;
} ;

// Base class for BGEN indices.
struct BgenIndex {
public:
	typedef std::unique_ptr< BgenIndex > UniquePtr ;

public:
	typedef std::pair< int64_t, int64_t> FilePosition ;
	typedef boost::tuple< std::string, uint32_t, uint32_t > Range ;
	typedef std::function< void ( std::size_t n, boost::optional< std::size_t > total ) > ProgressCallback ;

public:
	virtual ~BgenIndex() {} ;
	virtual FileMetadata const& file_metadata() const = 0 ;
	virtual void initialise(
		std::istream& stream,
		ProgressCallback callback = ProgressCallback()
	) = 0 ;
	virtual std::size_t number_of_variants() const = 0 ;
	virtual FilePosition position_of_variant( std::size_t index ) const = 0 ;
} ;

// BGEN index implemented using a sqlite file.
struct BgenSqliteIndex: public BgenIndex {
public:
	typedef std::unique_ptr< BgenSqliteIndex > UniquePtr ;

	BgenSqliteIndex( std::string const& filename, std::string const& table_name = "Variant" ):
		m_connection( open_connection( filename ) ),
		m_metadata( get_metadata( *m_connection ) ),
		m_index_table_name( table_name ),
		m_query_is_stale( true )
	{
	}
	
	FileMetadata const& file_metadata() const {
		return m_metadata ;
	}

	void initialise( std::istream& stream, ProgressCallback callback = ProgressCallback() ) {
		db::Connection::StatementPtr stmt = build_query() ;
		if( callback ) {
			callback( 0, boost::optional< std::size_t >() ) ;
		}
		m_positions.reserve( 1000000 ) ;
		std::size_t batch_i = 0 ;
		for( stmt->step() ; !stmt->empty(); stmt->step(), ++batch_i ) {
			int64_t const pos = stmt->get< int64_t >( 0 ) ;
			int64_t const size = stmt->get< int64_t >( 1 ) ;
			assert( pos >= 0 ) ;
			assert( size >= 0 ) ;
			m_positions.push_back( std::make_pair( int64_t( pos ), int64_t( size ))) ;
			if( callback ) {
				callback( m_positions.size(), boost::optional< std::size_t >() ) ;
			}
		}
#if DEBUG
		std::cerr << "BgenSqliteIndex::initialise(): read positions for " << m_positions.size() << " variants.\n" ;
#endif
		
		if( m_positions.size() > 0 ) {
			stream.seekg( m_positions[0].first ) ;
		}
		m_query_is_stale = false ;
	}

	std::size_t number_of_variants() const {
		return m_positions.size() ;
	}
	
	FilePosition position_of_variant( std::size_t index ) const {
#if DEBUG
		std::cerr << "BgenSqliteIndex::position_of_variant(" << index << ")...\n" ;
#endif
		assert( !m_query_is_stale ) ;
		assert( index < m_positions.size() ) ;
		return m_positions[index] ;
	}

public:
	BgenIndex& include_range( Range const& range ) {
		m_query_parts.inclusion += ((m_query_parts.inclusion.size() > 0) ? " OR " : "" ) + (
			boost::format( "( chromosome == '%s' AND position BETWEEN %d AND %d )" ) % range.get<0>() % range.get<1>() % range.get<2>()
		).str() ;
		m_query_is_stale = true ;
		return *this ;
	}

	BgenIndex& exclude_range( Range const& range ) {
		m_query_parts.exclusion += ( m_query_parts.exclusion.size() > 0 ? " AND" : "" ) + (
			boost::format( " NOT ( chromosome == '%s' AND position BETWEEN %d AND %d )" )
				% range.get<0>() % range.get<1>() % range.get<2>()
		).str() ;
		m_query_is_stale = true ;
		return *this ;
	}
	
	BgenIndex& include_rsids( std::vector< std::string > const& ids ) {
		m_connection->run_statement( "CREATE TEMP TABLE IF NOT EXISTS tmpIncludedId( identifier TEXT NOT NULL PRIMARY KEY ) WITHOUT ROWID" ) ;
		db::Connection::StatementPtr insert_stmt = m_connection->get_statement( "INSERT INTO tmpIncludedId( identifier ) VALUES( ? )" ) ;
		for( auto elt: ids ) {
			insert_stmt->bind( 1, elt ).step() ;
			insert_stmt->reset() ;
		}
		if( m_query_parts.join.find( "tmpIncludedId" ) == std::string::npos ) {
			m_query_parts.join += " LEFT OUTER JOIN tmpIncludedId TI ON TI.identifier == V.rsid" ;
			m_query_parts.inclusion += ( m_query_parts.inclusion.size() > 0 ? " OR" : "" ) + std::string( " TI.identifier IS NOT NULL" ) ;
		}
		m_query_is_stale = true ;
		return *this ;
	}
	
	BgenIndex& exclude_rsids( std::vector< std::string > const& ids ) {
		m_connection->run_statement( "CREATE TEMP TABLE IF NOT EXISTS tmpExcludedId( identifier TEXT NOT NULL PRIMARY KEY ) WITHOUT ROWID" ) ;
		db::Connection::StatementPtr insert_stmt = m_connection->get_statement( "INSERT INTO tmpExcludedId( identifier ) VALUES( ? )" ) ;
		for( auto elt: ids ) {
			insert_stmt->bind( 1, elt ).step() ;
			insert_stmt->reset() ;
		}
		if( m_query_parts.join.find( "tmpExcludedId" ) == std::string::npos ) {
			m_query_parts.join += " LEFT OUTER JOIN tmpExcludedId TE ON TE.identifier == V.rsid" ;
			m_query_parts.exclusion += ( m_query_parts.exclusion.size() > 0 ? " AND" : "" ) + std::string( " TE.identifier IS NULL" ) ;
		}
		m_query_is_stale = true ;
		return *this ;
	}

private:
	
	db::Connection::UniquePtr open_connection( std::string const& filename ) const {
		db::Connection::UniquePtr result ;
		try {
			result = db::Connection::create( filename, "r" ) ;
		} catch( db::ConnectionError const& e ) {
			throw std::invalid_argument( "Could not open index file." ) ;
		}
		return result ;
	}
	
	FileMetadata get_metadata( db::Connection& connection ) const {
		FileMetadata result ;
		db::Connection::StatementPtr stmt = connection.get_statement( "SELECT * FROM sqlite_master WHERE name == 'Metadata' AND type == 'table'" ) ;
		stmt->step() ;
		if( stmt->empty() ) {
			throw std::invalid_argument( "Index file appears malformed (no \"Metadata\" table)" ) ;
		}
		db::Connection::StatementPtr mdStmt = connection.get_statement( "SELECT filename, file_size, last_write_time, first_1000_bytes FROM Metadata" ) ;
		mdStmt->step() ;

		if( mdStmt->empty() ) {
			throw std::invalid_argument( "Index file appears malformed (empty \"Metadata\" table)" ) ;
		}
		// Get metadata fields for comparison
		result.filename = mdStmt->get< std::string >( 0 ) ;
		result.size = mdStmt->get< int64_t >( 1 ) ;
		result.last_write_time = mdStmt->get< int64_t >( 2 ) ;
		result.first_bytes = mdStmt->get< std::vector< uint8_t > >( 3 ) ;

		return result ;
	}
	
	db::Connection::StatementPtr build_query() const {
		std::string const select = "SELECT file_start_position, size_in_bytes FROM `"
			+ m_index_table_name + "` V" ;
		std::string const inclusion = ( m_query_parts.inclusion.size() > 0 ) ? ("(" + m_query_parts.inclusion + ")") : "" ;
		std::string const exclusion = ((m_query_parts.inclusion.size() > 0 && m_query_parts.exclusion.size() > 0 ) ? "AND " : "" )
			+ (( m_query_parts.exclusion.size() > 0 ) ? ("(" + m_query_parts.exclusion + ")") : "" ) ;
		std::string const where = (inclusion.size() > 0 || exclusion.size() > 0) ? ("WHERE " + inclusion + exclusion) : "" ;
		std::string const orderBy = "ORDER BY chromosome, position, rsid, allele1, allele2" ;
		std::string const select_sql = select + " " + m_query_parts.join + " " + where + " " + orderBy ;
#if DEBUG
		std::cerr << "BgenIndex::build_query(): SQL is: \"" << select_sql << "\"...\n" ;
#endif
		
		return m_connection->get_statement( select_sql ) ;
	}
	
private:
	db::Connection::UniquePtr m_connection ;
	FileMetadata const m_metadata ;
	std::string const m_index_table_name ;
	struct QueryParts {
		std::string join ;
		std::string inclusion ;
		std::string exclusion ;
	} ;
	QueryParts m_query_parts ;
	bool m_query_is_stale ;
	std::vector< std::pair< int64_t, int64_t> > m_positions ;
} ;

struct BgenView {
public:
	BgenView( std::string const& filename ) ;
	BgenView(
		std::string const& filename,
		BgenIndex::UniquePtr index,
		BgenIndex::ProgressCallback progress_callback = BgenIndex::ProgressCallback()
	) ;
	FileMetadata const& file_metadata() const ;
	genfile::bgen::Context const& context() const ;
	std::vector< byte_t > const& postheader_data() const ;
	std::streampos current_position() const ;
	uint32_t number_of_variants() const ;

	// Attempt to read identifying information about a variant from the bgen file, returning
	// it in the given fields.
	// If this method returns true, data was successfully read, and it should be safe to call
	// read_probability_data() or ignore_probability_data().
	// If this method returns false, data was not successfully read indicating the end of the file.
	// Following this method, you should call one of
	// read_probability_data()
	// read_and_unpack_v12_probability_data()
	// or ignore_probability_data().
	bool read_variant(
		std::string* SNPID,
		std::string* rsid,
		std::string* chromosome,
		uint32_t* position,
		std::vector< std::string >* alleles
	) ;

	// Option 1 is a full process.
	// This method reads and parse genotype probability data, returning data using
	// the bgen parse_probability_data API as documented on the wiki.
	// For an example using this API, see the bgen_to_vcf.cpp example program.
	template< typename ProbSetter >
	void read_probability_data( ProbSetter& setter ) {
		assert( m_state == e_ReadyForProbs ) ;
		genfile::bgen::read_and_parse_genotype_data_block< ProbSetter >(
			*m_stream,
			m_context,
			setter,
			&m_buffer1,
			&m_buffer2
		) ;
		m_file_position_of_current_variant = m_stream->tellg() ;
		m_state = e_ReadyForVariant ;
		++m_variant_i ;
	}
	
	// This method reads and uncompresses genotype probability data, and unpack
	// it into constituent parts, but don't do a full parse.
	// This can lead to more efficient code paths than a full parse for some operations.
	//
	// Currently this function works for 'layout=2' files, e.g. v1.2 and above only.
	// Data is returned in the fields of the supplied 'pack' object, which
	// is defined in bgen.hpp.
	void read_and_unpack_v12_probability_data(
		genfile::bgen::v12::GenotypeDataBlock* pack
	) ;

	// Ignore genotype probability data for the SNP just read using read_variant()
	// After calling this method it should be safe to call read_variant()
	// to fetch the next variant from the file.
	void ignore_probability_data() ;

private:

	// Open the bgen file, read header data and gather metadata.
	void setup( std::string const& filename ) ;

	// Verify that the given index matches this file using the supplied metadata.
	// Throw std::invalid_argument error if they mismatch, otherwise return the index.
	BgenIndex::UniquePtr verify_index( BgenIndex::UniquePtr& index ) const ;

	// Utility function to read and uncompress variant genotype probability data
	// without further processing.
	std::vector< byte_t > const& read_and_uncompress_probability_data() ;

private:
	std::string const m_filename ;
	std::unique_ptr< std::istream > m_stream ;
	std::size_t m_variant_i ;
	BgenIndex::UniquePtr m_index ;

	// meta data used to avoid stale index files.
	FileMetadata m_file_metadata ;

	// offset byte from top of bgen file.
	uint32_t m_offset ;

	// bgen::Context object holds information from the header block,
	// including bgen flags
	genfile::bgen::Context m_context ;

	// All data following header up to the first variant data block.
	std::vector< byte_t > m_postheader_data ;

	// We keep track of our state in the file.
	// This is not strictly necessary for this implentation but makes it clear that
	// the sequence of calls must be read_variant() followed by
	// ignore_probability_data() or ignore_probability_data() repeatedly.
	enum State { e_NotOpen = 0, e_Open = 1, e_ReadyForVariant = 2, e_ReadyForProbs = 3, eComplete = 4 } ;
	State m_state ;
	
	// To avoid issues with tellg() and failbit, we store the stream position at suitable points
	std::streampos m_file_position_of_current_variant ;
	
	// Two buffers for processing
	std::vector< byte_t > m_buffer1 ;
	std::vector< byte_t > m_buffer2 ;
} ;

/* BgenView implementation */

BgenView::BgenView( std::string const& filename ):
	m_filename( filename ),
	m_variant_i(0),
	m_state( e_NotOpen )
{
	setup( m_filename ) ;
	m_file_position_of_current_variant = m_stream->tellg() ;
}

BgenView::BgenView(
	std::string const& filename,
	BgenIndex::UniquePtr index,
	BgenIndex::ProgressCallback progress_callback
):
	m_filename( filename ),
	m_variant_i(0),
	m_state( e_NotOpen )
{
	setup( m_filename ) ;
	m_index = verify_index( index ) ;
	m_index->initialise( *m_stream, progress_callback ) ;
	if( m_index->number_of_variants() > 0 ) {
		m_stream->seekg( m_index->position_of_variant(0).first ) ;
	}
	m_file_position_of_current_variant = m_stream->tellg() ;
}


FileMetadata const& BgenView::file_metadata() const {
	return m_file_metadata ;
}

genfile::bgen::Context const& BgenView::context() const {
	return m_context ;
}

std::vector< byte_t > const& BgenView::postheader_data() const {
	return m_postheader_data ;
}

std::streampos BgenView::current_position() const {
	return m_file_position_of_current_variant ;
}

uint32_t BgenView::number_of_variants() const {
	if( m_index ) {
		return m_index->number_of_variants() ;
	} else {
		return m_context.number_of_variants ;
	}
}

// Attempt to read identifying information about a variant from the bgen file, returning
// it in the given fields.
// If this method returns true, data was successfully read, and it should be safe to call
// read_probability_data() or ignore_probability_data().
// If this method returns false, data was not successfully read indicating the end of the file.
bool BgenView::read_variant(
	std::string* SNPID,
	std::string* rsid,
	std::string* chromosome,
	uint32_t* position,
	std::vector< std::string >* alleles
) {
	assert( m_state == e_ReadyForVariant ) ;

	if( m_index ) {
		BgenIndex::FilePosition const pos = m_index->position_of_variant( m_variant_i ) ;
		m_stream->seekg( pos.first ) ;
	}

	if(
		genfile::bgen::read_snp_identifying_data(
			*m_stream, m_context,
			SNPID, rsid, chromosome, position,
			[&alleles]( std::size_t n ) { alleles->resize( n ) ; },
			[&alleles]( std::size_t i, std::string const& allele ) { alleles->at(i) = allele ; }
		)
	) {
		m_state = e_ReadyForProbs ;
		return true ;
	} else {
		return false ;
	}
}

// Read and uncompress genotype probability data, and unpack
// it into constituent parts, but don't do a full parse.
// This can lead to more efficient code paths than a full parse for some operations.
//
// Currently this function works for 'layout=2' files, e.g. v1.2 and above only.
// Data is returned in the fields of the supplied 'pack' object, which
// is defined in bgen.hpp.
void BgenView::read_and_unpack_v12_probability_data(
	genfile::bgen::v12::GenotypeDataBlock* pack
) {
	assert( (m_context.flags & genfile::bgen::e_Layout) == genfile::bgen::e_Layout2 ) ;
	std::vector< byte_t > const& buffer = read_and_uncompress_probability_data() ;
	pack->initialise( m_context, &buffer[0], &buffer[0] + buffer.size() ) ;
	++m_variant_i ;
}

// Ignore genotype probability data for the SNP just read using read_variant()
// After calling this method it should be safe to call read_variant()
// to fetch the next variant from the file.
void BgenView::ignore_probability_data() {
	assert( m_state == e_ReadyForProbs ) ;
	genfile::bgen::ignore_genotype_data_block( *m_stream, m_context ) ;
	m_file_position_of_current_variant = m_stream->tellg() ;
	m_state = e_ReadyForVariant ;
	++m_variant_i ;
}

// Open the bgen file, read header data and gather metadata.
void BgenView::setup( std::string const& filename ) {
	m_file_metadata.filename = filename ;
	m_file_metadata.last_write_time = boost::filesystem::last_write_time( filename ) ;

	// Open the stream
	m_stream.reset(
		new std::ifstream( filename, std::ifstream::binary )
	) ;
	if( !*m_stream ) {
		throw std::invalid_argument( filename ) ;
	}

	// get file size
	{
		std::ios::streampos origin = m_stream->tellg() ;
		m_stream->seekg( 0, std::ios::end ) ;
		m_file_metadata.size = m_stream->tellg() - origin ;
		m_stream->seekg( 0, std::ios::beg ) ;
	}
	// read first (up to) 1000 bytes.
	{
		m_file_metadata.first_bytes.resize( 1000, 0 ) ;
		m_stream->read( reinterpret_cast< char* >( &m_file_metadata.first_bytes[0] ), 1000 ) ;
		m_file_metadata.first_bytes.resize( m_stream->gcount() ) ;
		m_stream->clear() ;
		m_stream->seekg( 0, std::ios::beg ) ;
	}

	m_state = e_Open ;

	// Read the offset, header, and sample IDs if present.
	genfile::bgen::read_offset( *m_stream, &m_offset ) ;
	genfile::bgen::read_header_block( *m_stream, &m_context ) ;

	// read data up to first data block.
	m_postheader_data.reserve( m_offset - m_context.header_size() ) ;
	m_stream->read( reinterpret_cast< char* >( &m_postheader_data[0] ), m_postheader_data.size() ) ;
	if( m_stream->gcount() != m_postheader_data.size() ) {
		throw std::invalid_argument(
			(
				boost::format(
					"BGEN file (\"%s\") appears malformed - offset specifies more bytes (%d) than are in the file."
				) % filename % m_offset
			).str()
		) ;
	}

	// We keep track of state (though it's not really needed for this implementation.)
	m_state = e_ReadyForVariant ;
}

// Verify that the given index matches this file using the supplied metadata.
// Throw std::invalid_argument error if they mismatch, otherwise return the index.
BgenIndex::UniquePtr BgenView::verify_index( BgenIndex::UniquePtr& index ) const {
	if( index->file_metadata().size != m_file_metadata.size ) {
		std::string const message = "!! Size of file (\"" + m_filename + "\" ("
			+ std::to_string( m_file_metadata.size ) + " bytes)"
			+ "differs from that recorded in the index file ("
			+ std::to_string( index->file_metadata().size ) + ").\n"
			+ "Do you need to recreate the index?\n" ;
		throw std::invalid_argument( message ) ;
		//throw appcontext::HaltProgramWithReturnCode( -1 ) ;
	}

	if( index->file_metadata().first_bytes != m_file_metadata.first_bytes ) {
		std::string const message = "!! File (\"" + m_filename + "\" has different initial bytes"
			+ " than recorded in the index file - that can't be right.\n"
			+ "Do you need to recreate the index?\n" ;
		throw std::invalid_argument( message ) ;
		//throw appcontext::HaltProgramWithReturnCode( -1 ) ;
	}
	return std::move( index ) ;
}

// Utility function to read and uncompress variant genotype probability data
// without further processing.
std::vector< byte_t > const& BgenView::read_and_uncompress_probability_data() {
	assert( m_state == e_ReadyForProbs ) ;
	genfile::bgen::read_genotype_data_block( *m_stream, m_context, &m_buffer1 ) ;
	m_file_position_of_current_variant = m_stream->tellg() ;
	m_state = e_ReadyForVariant ;
	genfile::bgen::uncompress_probability_data( m_context, m_buffer1, &m_buffer2 ) ;
	return m_buffer2 ;
}

/* IndexBgenApplication */
struct IndexBgenApplication: public appcontext::ApplicationContext
{
public:
	IndexBgenApplication( int argc, char** argv ):
		appcontext::ApplicationContext(
			globals::program_name,
			globals::program_version,
			std::auto_ptr< appcontext::OptionProcessor >( new IndexBgenOptionProcessor ),
			argc,
			argv,
			"-log"
		)
	{
		setup() ;
	}

private:
	std::string m_bgen_filename ;
	std::string m_index_filename ;

private:
	void setup() {
		m_bgen_filename = options().get< std::string >( "-g" ) ;
		m_index_filename = m_bgen_filename + ".bgi" ;
		if( !bfs::exists( m_bgen_filename )) {
			ui().logger() << "!! Error, the BGEN file \"" << m_bgen_filename << "\" does not exist!\n" ;
			throw std::invalid_argument( m_bgen_filename ) ;
		}
		if( options().check( "-index" )) {
			if( bfs::exists( m_index_filename ) && !options().check( "-clobber" )) {
				ui().logger() << "!! Error, the index file \"" + m_index_filename + "\" already exists, use -clobber if you want to overwrite it.\n" ;
				throw appcontext::HaltProgramWithReturnCode( -1 ) ;
			} else {
				create_bgen_index( m_bgen_filename, m_index_filename ) ;
			}
		} else {
			process_selection( m_bgen_filename, m_index_filename ) ;
		}
	}

	void create_bgen_index( std::string const& bgen_filename, std::string const& index_filename ) {
		db::Connection::UniquePtr result ;
		ui().logger()
			<< boost::format( "%s: creating index for \"%s\" in \"%s\"...\n" ) % globals::program_name % bgen_filename % index_filename ;

		try {
			if( bfs::exists( index_filename + ".tmp" ) && !options().check( "-clobber" ) ) {
				ui().logger() << "!! Error, an incomplete index file \"" + (index_filename + ".tmp") + "\" exists.\n"
					"This probably reflects a bgenix job that was terminated.\n"
					"Use -clobber to overwrite (or delete the file).\n" ;
				throw std::invalid_argument( index_filename ) ;
			}
			result = create_bgen_index_unsafe( bgen_filename, index_filename + ".tmp" ) ;
			bfs::rename( index_filename + ".tmp", index_filename ) ;
		} catch( db::StatementStepError const& e ) {
			ui().logger() << "!! Error in \"" << e.spec() << "\": " << e.description() << ".\n" ;
			bfs::remove( index_filename + ".tmp" ) ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		} catch( ... ) {
			// Remove the incomplete attempt at an index file.
			bfs::remove( index_filename + ".tmp" ) ;
			throw ;
		}
	}
	
	db::Connection::UniquePtr create_bgen_index_unsafe( std::string const& bgen_filename, std::string const& index_filename ) {
		db::Connection::UniquePtr connection = db::Connection::create( index_filename, "rw" ) ;

		connection->run_statement( "PRAGMA locking_mode = EXCLUSIVE ;" ) ;
		connection->run_statement( "PRAGMA journal_mode = MEMORY ;" ) ;
		
		db::Connection::ScopedTransactionPtr transaction = connection->open_transaction( 240 ) ;
		setup_index_file( *connection ) ;
		// Close and open the transaction
		transaction.reset() ;

		db::Connection::StatementPtr insert_metadata_stmt = connection->get_statement(
			"INSERT INTO Metadata( filename, file_size, last_write_time, first_1000_bytes, index_creation_time ) VALUES( ?, ?, ?, ?, ? )"
		) ;

		db::Connection::StatementPtr insert_variant_stmt = connection->get_statement(
			"INSERT INTO Variant( chromosome, position, rsid, number_of_alleles, allele1, allele2, file_start_position, size_in_bytes ) "
			"VALUES( ?, ?, ?, ?, ?, ?, ?, ? )"
		) ;

		BgenView bgenView( bgen_filename ) ;
		
		insert_metadata_stmt
			->bind( 1, bgen_filename )
			.bind( 2, bgenView.file_metadata().size )
			.bind( 3, uint64_t( bgenView.file_metadata().last_write_time ) )
			.bind( 4, &bgenView.file_metadata().first_bytes[0], &bgenView.file_metadata().first_bytes[0] + bgenView.file_metadata().first_bytes.size() )
			.bind( 5, appcontext::get_current_time_as_string() )
			.step() ;

		ui().logger()
			<< boost::format( "%s: Opened \"%s\" with %d variants...\n" ) % globals::program_name % bgen_filename % bgenView.number_of_variants() ;
		
		std::string chromosome, rsid, SNPID ;
		uint32_t position ;
		std::vector< std::string > alleles ;
		alleles.reserve(100) ;
		std::size_t const chunk_size = 10 ;
		
		transaction = connection->open_transaction( 240 ) ;
		
		{
			auto progress_context = ui().get_progress_context( "Building BGEN index" ) ;
			std::size_t variant_count = 0;
			int64_t file_pos = int64_t( bgenView.current_position() ) ;
			try {
				while( bgenView.read_variant( &SNPID, &rsid, &chromosome, &position, &alleles ) ) {
#if DEBUG
					std::cerr << "read variant:" << chromosome << " " << position << " " << rsid << " " << file_pos << " " << alleles.size() << ".\n" << std::flush ;
					std::cerr << "alleles: " << alleles[0] << ", "  << alleles[1] << ".\n" << std::flush ;
#endif
					bgenView.ignore_probability_data() ;
					int64_t file_end_pos = int64_t( bgenView.current_position() ) ;
					assert( alleles.size() > 1 ) ;
					assert( (file_end_pos - file_pos) > 0 ) ;
					insert_variant_stmt
						->bind( 1, chromosome )
						.bind( 2, position )
						.bind( 3, rsid )
						.bind( 4, int64_t( alleles.size() ) )
						.bind( 5, alleles[0] )
						.bind( 6, alleles[1] )
						.bind( 7, file_pos )
						.bind( 8, file_end_pos - file_pos )
						.step()
					;
					insert_variant_stmt->reset() ;
				
					progress_context( ++variant_count, bgenView.number_of_variants() ) ;
			
				// Make sure and commit every 10000 SNPs.
					if( variant_count % chunk_size == 0 ) {
		//				ui().logger()
		//					<< boost::format( "%s: Writing variants %d-%d...\n" ) % bgenView.number_of_variants() % (variant_count-chunk_size) % (variant_count-1) ;
					
						transaction.reset() ;
						transaction = connection->open_transaction( 240 ) ;
					}
					file_pos = file_end_pos ;
#if DEBUG
					std::cerr << "Record inserted.\n" << std::flush ;
#endif
								}
			}
			catch( genfile::bgen::BGenError const& e ) {
				ui().logger() << "!! (" << e.what() << "): an error occurred reading from the input file.\n" ;
				ui().logger() << "Last observed variant was \"" << SNPID.substr(0,10) << "\", \"" << rsid.substr(0,10) << "\"...\n" ;
				ui().logger() << "Reached byte " << file_pos << " in input file, which has size " << bgenView.file_metadata().size << ".\n" ;
				throw ;
			}
 			catch( db::StatementStepError const& e ) {
				ui().logger() << "Last observed variant was " << SNPID << " " << rsid << " " << chromosome << " " << position ;
				for( std::size_t i = 0; i < alleles.size(); ++i ) {
					ui().logger() << " " << alleles[i] ;
				}
				ui().logger() << "\n" ;
				ui().logger() << "Reached byte " << file_pos << " in input file, which has size " << bgenView.file_metadata().size << ".\n" ;
				throw ;
			}
		}
		return connection ;
	}
	
	void setup_index_file( db::Connection& connection ) {
		std::string const tag = options().check( "-with-rowid" ) ? "" : " WITHOUT ROWID" ;

		connection.run_statement(
			"CREATE TABLE Metadata ("
			" filename TEXT NOT NULL,"
			" file_size INT NOT NULL,"
			" last_write_time INT NOT NULL,"
			" first_1000_bytes BLOB NOT NULL,"
			" index_creation_time INT NOT NULL"
			")"
		) ;

		connection.run_statement(
			"CREATE TABLE Variant ("
			"  chromosome TEXT NOT NULL,"
			"  position INT NOT NULL,"
			"  rsid TEXT NOT NULL,"
			"  number_of_alleles INT NOT NULL,"
			"  allele1 TEXT NOT NULL,"
			"  allele2 TEXT NULL,"
			"  file_start_position INT NOT NULL," // 
			"  size_in_bytes INT NOT NULL,"       // We put these first to minimise cost of retrieval
			"  PRIMARY KEY (chromosome, position, rsid, allele1, allele2, file_start_position )"
			")" + tag
		) ;
	}
	
	void process_selection( std::string const& bgen_filename, std::string const& index_filename ) const {
		try {
			process_selection_unsafe( bgen_filename, index_filename ) ;
		}
		catch( ... ) {
			throw ;
		}
	}

	void process_selection_unsafe( std::string const& bgen_filename, std::string const& index_filename ) const {
		BgenSqliteIndex::UniquePtr index ;
		try {
			index.reset( new BgenSqliteIndex( index_filename ) ) ;
		} catch( std::invalid_argument const& e ) {
			std::cerr << "!! Error opening index file \"" << index_filename
				<< "\": " << e.what() << "\n" ;
			std::cerr << "Do you need to regenerate the index file?\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
		
		setup_query( *index ) ;
		
		//setup_query( *index ) ;
		bool const transcode
			= options().check( "-list" )
			|| options().check( "-vcf" )
			|| options().check( "-v11" ) ;

		if( transcode ) {
			BgenView bgenView( bgen_filename, std::move( index ) ) ;
			if( options().check( "-list" ) ) {
				process_selection_list( bgenView ) ;
			} else if( options().check( "-vcf" )) {
				process_selection_transcode( bgenView, "vcf" ) ;
			} else if( options().check( "-v11" )) {
				process_selection_transcode( bgenView, "bgen_v1.1" ) ;
			}
		} else {
			process_selection_notranscode( bgen_filename, std::move( index ) ) ;
		}
	}

	void setup_query( BgenSqliteIndex& index ) const {
		if( options().check( "-incl-range" )) {
			auto const elts = collect_unique_ids( options().get_values< std::string >( "-incl-range" ));
			for( std::string const& elt: elts ) {
				index.include_range( parse_range( elt )) ;
			}
		}
		if( options().check( "-excl-range" )) {
			auto const elts = collect_unique_ids( options().get_values< std::string >( "-excl-range" ));
			for( std::string const& elt: elts ) {
				index.exclude_range( parse_range( elt )) ;
			}
		}
		if( options().check( "-incl-rsids" )) {
			auto const ids = collect_unique_ids( options().get_values< std::string >( "-incl-rsids" ));
			index.include_rsids( ids ) ;
		}

		if( options().check( "-excl-rsids" )) {
			auto const ids = collect_unique_ids( options().get_values< std::string >( "-excl-rsids" ));
			index.exclude_rsids( ids ) ;
		}
	}
	
	std::vector< std::string > collect_unique_ids( std::vector< std::string > const& ids_or_filenames ) const {
		std::vector< std::string > result ;
		for( auto elt: ids_or_filenames ) {
			if( bfs::exists( elt )) {
				std::ifstream f( elt ) ;
				std::copy(
					std::istream_iterator< std::string >( f ),
					std::istream_iterator< std::string >(),
					std::back_inserter< std::vector< std::string > >( result )
				) ;
			} else {
				result.push_back( elt ) ;
			}
		}
		// now sort and uniqueify them...
		std::sort( result.begin(), result.end() ) ;
		std::vector< std::string >::const_iterator newBack = std::unique( result.begin(), result.end() ) ;
		result.resize( newBack - result.begin() ) ;
		return result ;
	}

	void process_selection_notranscode( std::string const& bgen_filename, BgenIndex::UniquePtr index ) const {
		std::ifstream bgen_file( bgen_filename, std::ios::binary ) ;
		uint32_t offset = 0 ;

		using namespace genfile ;
		bgen::Context context ;
		bgen::read_offset( bgen_file, &offset ) ;
		bgen::read_header_block( bgen_file, &context ) ;

		// Write the new context after adjusting the variant count.
		context.number_of_variants = index->number_of_variants() ;
		bgen::write_offset( std::cout, offset ) ;
		bgen::write_header_block( std::cout, context ) ;
		std::istreambuf_iterator< char > inIt( bgen_file ) ;
		std::istreambuf_iterator< char > endInIt ;
		std::ostreambuf_iterator< char > outIt( std::cout ) ;

		// Copy everything else up to the start of the data
		std::copy_n( inIt, offset - context.header_size(), outIt ) ;

		{
			auto progress_context = ui().get_progress_context( "Processing " + std::to_string( index->number_of_variants() ) + " variants" ) ;
			// Now we go for it
			for( std::size_t i = 0; i < index->number_of_variants(); ++i ) {
				std::pair< int64_t, int64_t> range = index->position_of_variant( i ) ;
				bgen_file.seekg( range.first ) ;
				std::istreambuf_iterator< char > inIt( bgen_file ) ;
				std::copy_n( inIt, range.second, outIt ) ;
				progress_context( i+1, index->number_of_variants() ) ;
			}
		}
		std::cerr << boost::format( "%s: wrote data for %d variants to stdout.\n" ) % globals::program_name % index->number_of_variants() ;
	}
	
	void process_selection_list( BgenView& bgenView ) const {
		std::cout << boost::format( "# %s: started %s\n" ) % globals::program_name % appcontext::get_current_time_as_string() ;
		std::cout << "alternate_ids\trsid\tchromosome\tposition\tnumber_of_alleles\tfirst_allele\talternative_alleles\n" ;
		
		std::string SNPID, rsid, chromosome ;
		uint32_t position ;
		std::vector< std::string > alleles ;

		for( std::size_t i = 0; i < bgenView.number_of_variants(); ++i ) {
			bool success = bgenView.read_variant(
				&SNPID, &rsid, &chromosome, &position, &alleles
			) ;
			if( SNPID.empty() ) {
				SNPID = "." ;
			}
			if( rsid.empty() ) {
				rsid = "." ;
			}
			std::cout << SNPID << "\t" << rsid << "\t" << chromosome << "\t" << position << "\t" << alleles.size() << "\t" << alleles[0] << "\t" ;
			for( std::size_t allele_i = 1; allele_i < alleles.size(); ++allele_i ) {
				std::cout << (( allele_i > 1 ) ? "," : "" ) << alleles[allele_i] ;
			}
			std::cout << "\n" ;
			if( !success ) {
				throw std::invalid_argument( "positions" ) ;
			}
			bgenView.ignore_probability_data() ;
		}
		std::cout << boost::format( "# %s: success, total %d variants.\n" ) % globals::program_name % bgenView.number_of_variants() ;
	}

	void process_selection_transcode(
		BgenView& view,
		std::string const& format
	) const {
		if( format == "vcf" ) {
			process_selection_transcode_bgen_vcf( view ) ;
		} else if( format == "bgen_v1.1" ) {
			process_selection_transcode_bgen_v11( view ) ;
		} else {
			throw std::invalid_argument( "format=\"" + format + "\"" ) ;
		}
	}

	struct VCFProbWriter {
		VCFProbWriter( std::ostream& out ):
			m_out( out )
		{}
		
		// Called once allowing us to set storage.
		void initialise( std::size_t number_of_samples, std::size_t number_of_alleles ) {
			// Nothing to do.
			m_number_of_alleles = number_of_alleles ;
		}
	
		// If present with this signature, called once after initialise()
		// to set the minimum and maximum ploidy and numbers of probabilities among samples in the data.
		// This enables us to set up storage for the data ahead of time.
		void set_min_max_ploidy( uint32_t min_ploidy, uint32_t max_ploidy, uint32_t min_entries, uint32_t max_entries ) {
			// Make sure we've enough space.
			m_data.reserve( max_entries ) ;
		}
	
		// Called once per sample to determine whether we want data for this sample
		bool set_sample( std::size_t i ) {
			// Yes, here we want info for all samples.
			return true ;
		}
	
		// Called once per sample to set the number of probabilities that are present.
		void set_number_of_entries(
			std::size_t ploidy,
			std::size_t number_of_entries,
			genfile::OrderType order_type,
			genfile::ValueType value_type
		) {
			assert( value_type == genfile::eProbability ) ;
			m_data.resize( number_of_entries ) ;
			m_out << "\t" ;
			m_ploidy = ploidy ;
			m_order_type = order_type ;
			m_missing = false ;
		}

		void set_value( uint32_t entry_i, double value ) {
			m_data[ entry_i ] = value ;
			if( entry_i == m_data.size() - 1 ) {
				write_sample_entry() ;
			}
		}

		void set_value( uint32_t entry_i, genfile::MissingValue value ) {
			m_data[ entry_i ] = -1 ;
			m_missing = true ;
			if( entry_i == m_data.size() - 1 ) {
				write_sample_entry() ;
			}
		}


		// If present with this signature, called once after all data has been set.
		void finalise() {
			m_out << "\n" ;
		}

	private:
		std::ostream& m_out ;
		std::vector< double > m_data ;
		std::size_t m_number_of_alleles ;

		// Used to keep track of what we're doing.
		std::size_t m_ploidy ;
		genfile::OrderType m_order_type ;
		bool m_missing ;
		
		// These fields are used to enumerate genotypes for the GT field.
		std::vector< uint16_t > m_allele_count_limits ;
		std::vector< uint16_t > m_allele_counts ;
		
		// space to assemble GT field.
		std::string m_GT_buffer ;
		void write_sample_entry() {
			if( m_missing ) {
				std::string const GT_separator = (m_order_type == genfile::ePerPhasedHaplotypePerAllele) ? "|" : "/" ;
				for( uint32_t i = 0 ; i < m_ploidy; ++i ) {
					m_out << ((i>0) ? GT_separator : "" )
						<< "." ;
				}
				m_out << ":" ;
				for( std::size_t i = 0; i < m_data.size(); ++i ) {
					m_out << m_data[i] ;
				}
			} else {
				std::string const& GT = construct_GT( m_data, 0.9 ) ;
				
				m_out << "\t"
					<< GT
					<< ":" ;
				for( std::size_t i = 0; i < m_data.size(); ++i ) {
					m_out << ((i>0) ? "," : "") ;
					if( m_data[i] == -1 ) {
						m_out << "." ;
					} else {
						m_out << m_data[i] ;
					}
				}
			}
		}

		std::string const& construct_GT( std::vector< double > const& probs, double const threshhold ) {
			if( m_order_type == genfile::ePerPhasedHaplotypePerAllele ) {
				return construct_phased_GT( probs, threshhold ) ;
			} else {
				return construct_unphased_GT( probs, threshhold ) ;
			}
		}

		std::string const& construct_phased_GT( std::vector< double > const& probs, double const threshhold ) {
			m_GT_buffer.clear() ;
			// for phased data it is simple:
			for( uint32_t i = 0; i < m_ploidy; ++i ) {
				uint32_t j = 0 ;
				for( ; j < m_number_of_alleles; ++j ) {
					if( probs[i*m_number_of_alleles+j] > threshhold ) {
						break ;
					}
				}
				if( j < m_number_of_alleles ) {
					m_GT_buffer += std::to_string( j ) + "|" ;
				} else {
					m_GT_buffer += ".|" ;
				}
			}
			// remove trailing separator
			m_GT_buffer.resize( m_GT_buffer.size() - 1 ) ;
			return m_GT_buffer ;
		}

		std::string const& construct_unphased_GT( std::vector< double > const& probs, double const threshhold ) {
			// To construct the GT field for unphased data, we must enumerate
			// all of the possible genotypes.
			// These come in colex order of the the allele count representation.
			// Specifically, we have m_ploidy = n chromosomes in total.
			// Genotypes are all ways to put n_alleles = k alleles into those chromosomes.
			// We represent these as k-vectors that sum to n (i.e. v_i is the count of allele i)
			// Or (k-1)-vectors that sum to at most n.
			// The colex order implies that lower indices are always used first.
			// E.g. for ploidy = 3 and 3 alleles, the order is
			// 3,0,0 = AAA
			// 2,1,0 = AAB
			// 1,2,0 = ABB
			// 0,3,0 = BBB
			// 2,0,1 = BBC
			// 1,1,1 = ABC
			// 0,2,1 = BBC
			// 0,1,2 = BCC
			// 0,0,3 = CCC
			// Here we enumerate these and bail out when we hit a probability over the threshhold.
			m_allele_count_limits.assign( (m_number_of_alleles-1), m_ploidy ) ;
			m_allele_counts.assign( m_number_of_alleles, 0 ) ;
			// Set up first genotype - all ref allele
			m_allele_counts[0] = m_ploidy ;

			// Iterate through genotypes.
			bool metThreshhold = false ;
			for( std::size_t index = 0; true; ++index ) {
				if( probs[index] > threshhold ) {
					metThreshhold = true ;
					break ;
				}
				
				// Move to next possible genotype
				std::size_t j = 0 ;
				for( ; j < (m_number_of_alleles-1); ++j ) {
					uint16_t value = m_allele_counts[j+1] ;
					if( value < m_allele_count_limits[ j ] ) {
						++m_allele_counts[j+1] ;
						--m_allele_counts[0] ;
						for( std::size_t k = 0; k < j; ++k ) {
							--m_allele_count_limits[k] ;
						}
						break ;
					} else {
						// allele count has reached its limit.
						// Reset it to zero.
						// Note that to get here all lower-order counts must be zero.
						m_allele_counts[j+1] = 0 ;
						m_allele_counts[0] += value ;
						for( std::size_t k = 0; k < j; ++k ) {
							m_allele_count_limits[k] += value ;
						}
					}
				}
				if( j == (m_number_of_alleles-1) ) {
					break ;
				}
			}
			
			m_GT_buffer.clear() ;
			if( metThreshhold ) {
				for( std::size_t allele = 0; allele < m_number_of_alleles; ++allele ) {
					std::string const elt = std::to_string( allele ) + "/" ;
					for( uint16_t count = 0; count < m_allele_counts[allele]; ++count ) {
						m_GT_buffer += elt ;
					}
				}
			} else {
				for( std::size_t i = 0; i < m_ploidy; ++i ) {
					m_GT_buffer += "./" ;
				}
			}
			// remove trailing slash.
			m_GT_buffer.resize( m_GT_buffer.size() - 1 ) ;
			return m_GT_buffer ;
		}
	} ;

	void process_selection_transcode_bgen_vcf(
		BgenView& bgenView
	) const {
		std::cout << "##fileformat=VCFv4.2\n"
			<< "FORMAT=<ID=GT,Type=String,Number=1,Description=\"Threshholded genotype call\">\n"
			<< "FORMAT=<ID=GP,Type=Float,Number=G,Description=\"Genotype call probabilities\">\n"
			<< "FORMAT=<ID=HP,Type=Float,Number=.,Description=\"Haplotype call probabilities\">\n"
			<< "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT" ;
		
		std::cout << "\n" ;
		std::string SNPID, rsid, chromosome ;
		uint32_t position ;
		std::vector< std::string > alleles ;

		for( std::size_t i = 0; i < bgenView.number_of_variants(); ++i ) {
			bool success = bgenView.read_variant(
				&SNPID, &rsid, &chromosome, &position, &alleles
			) ;
			assert( success ) ;
			assert( alleles.size() > 1 ) ;
			std::cout << chromosome
				<< "\t" << position
				<< "\t" << alleles[0]
				<< "\t" ;
			for( std::size_t j = 1; j < alleles.size(); ++j ) {
				std::cout << ((j==1)?"":",") << alleles[j] ;
			}
			std::cout
				<< "\t"
				<< ".\t" // QUAL
				<< ".\t" // FILTER
				<< ".\t" // INFO
				<< "GT:GP\t" // FORMAT
			;
			VCFProbWriter writer( std::cout ) ;
			bgenView.read_probability_data( writer ) ;
		}
	}
	
	// This function implements an efficient transcode from a specific type of BGEN file
	// To BGEN v1.1 files.
	// Specifically we support BGEN 'layout=2' files (BGEN v1.2 and above) with 8 bits per
	// probability.
	// For efficiency, instead of a full parse we extract encoded data and use a lookup table
	// to generate BGEN v1.1 values for encoding.
	void process_selection_transcode_bgen_v11(
		BgenView& bgenView
	) const {
		// Currently this is only supported in a very restricted scenario.
		// Namely, when the format is BGEN v1.2, unphased data, encoded
		// with 8 bits per probability, converting to a BGEN v1.1 file.
		// And all variants must be biallelic.
		uint32_t const inputLayout = bgenView.context().flags & genfile::bgen::e_Layout ;
		if( inputLayout != genfile::bgen::e_Layout2 ) {
			throw std::invalid_argument( "bgen_filename=\"" + bgenView.file_metadata().filename + "\"" ) ;
		}

		// specify flags for BGEN v1.1
		// This means layout 1, no sample identifiers, zlib compression.
		genfile::bgen::Context outputContext = bgenView.context() ;
		outputContext.flags = genfile::bgen::e_Layout1 | genfile::bgen::e_ZlibCompression ;
		
		// Write offset and header
		genfile::bgen::write_offset( std::cout, outputContext.header_size() ) ;
		genfile::bgen::write_header_block( std::cout, outputContext ) ;

		// We require two buffers: one to serialise data to,
		// and one to assemble final compressed result to.
		std::vector< byte_t > serialisationBuffer( 6 * outputContext.number_of_samples ) ;
		std::vector< byte_t > idDataBuffer ;
		std::vector< byte_t > compressionBuffer ;

		std::string SNPID, rsid, chromosome ;
		uint32_t position ;
		std::vector< std::string > alleles ;

		std::vector< uint64_t > probability_encoding_table = compute_probability_encoding_table() ;

		{
			auto progress_context = ui().get_progress_context( "Processing " + std::to_string( bgenView.number_of_variants() ) + " variants" ) ;
			for( std::size_t i = 0; i < bgenView.number_of_variants(); ++i ) {
				bool success = bgenView.read_variant(
					&SNPID, &rsid, &chromosome, &position, &alleles
				) ;
				assert( success ) ;
				if( alleles.size() != 2 ) {
					std::cerr
						<< "In -transcode, found variant with " << alleles.size() << " allele, only 2 alleles are supported by BGEN v1.1.\n" ;
					throw std::invalid_argument( "bgen_filename=\"" + bgenView.file_metadata().filename + "\"" ) ;
				}
				
				genfile::bgen::write_snp_identifying_data(
					&idDataBuffer,
					outputContext,
					SNPID, rsid, chromosome, position,
					uint16_t( 2 ), 
					[&alleles](std::size_t i) { return alleles[i] ; }
				) ;

				genfile::bgen::v12::GenotypeDataBlock pack ;
				bgenView.read_and_unpack_v12_probability_data( &pack ) ;

				if( pack.bits != 8 ) {
					std::cerr << "For -v11, expected 8 bits per probability, found " << pack.bits << ".\n" ;
					throw std::invalid_argument( "bgen_filename=\"" + bgenView.file_metadata().filename + "\"" ) ;
				}
				if( pack.phased != 0 ) {
					std::cerr << "For -v11, expected unphased data.\n" ;
					throw std::invalid_argument( "bgen_filename=\"" + bgenView.file_metadata().filename + "\"" ) ;
				}
				if( pack.end < pack.buffer + bgenView.context().number_of_samples ) {
					throw std::invalid_argument( "bgen_filename=\"" + bgenView.file_metadata().filename + "\"" ) ;
				}
				byte_t* out_p = &serialisationBuffer[0] ;
				byte_t const* p = pack.ploidy ;
				byte_t const* buffer = pack.buffer ;
				for( ; p < (pack.ploidy + pack.numberOfSamples); ++p, buffer += 2 ) {
					if( *p & byte_t( 0x80 ) ) {
						// data is missing, encode as zeros.
						*out_p++ = 0 ; *out_p++ = 0 ;
						*out_p++ = 0 ; *out_p++ = 0 ;
						*out_p++ = 0 ; *out_p++ = 0 ;
					} else {
						std::size_t const key = *reinterpret_cast< uint16_t const* >( buffer ) ;
						assert( key < probability_encoding_table.size() ) ;
						uint64_t const value = probability_encoding_table[ *reinterpret_cast< uint16_t const* >( buffer ) ] ;
#if DEBUG
						std::cerr << ( boost::format( "%d, %d" ) % key % probability_encoding_table.size() ) << "\n" ;
						std::cerr << ( boost::format( "%x: %x" ) % key % value ) << "\n" ;
						std::cerr << "Input: " << uint64_t(*reinterpret_cast< uint8_t const* >( buffer )) << ", " << uint64_t(*reinterpret_cast< uint8_t const* >( buffer+1 )) << "\n" ;
						std::cerr << "Output: " << uint64_t( value & 0xFFFF) << ", " << uint64_t( (value>>16) & 0xFFFF) << ", " << uint64_t( (value>>32) & 0xFFFF) << ".\n" ;
#endif
						*out_p++ = ( (value >> 0) & 0xFF ) ;
						*out_p++ = ( (value >> 8) & 0xFF ) ;
						*out_p++ = ( (value >> 16) & 0xFF ) ;
						*out_p++ = ( (value >> 24) & 0xFF ) ;
						*out_p++ = ( (value >> 32) & 0xFF ) ;
						*out_p++ = ( (value >> 40) & 0xFF ) ;
					}
				}
			
				// Compress it.
				assert( out_p == &serialisationBuffer[0] + serialisationBuffer.size() ) ;
				genfile::zlib_compress(
					serialisationBuffer,
					&compressionBuffer,
					1 // compression level
				) ;
#if DEBUG
				std::cerr << ( boost::format( "serialisation buffer: %d, id data Buffer: %d, result buffer: %d" ) % serialisationBuffer.size() % idDataBuffer.size() % compressionBuffer.size() ) << "\n" ;
#endif
				std::ostreambuf_iterator< char > outIt( std::cout ) ;
				std::copy( &idDataBuffer[0], &idDataBuffer[0]+idDataBuffer.size(), outIt ) ;
				genfile::bgen::write_little_endian_integer(
					std::cout,
					uint32_t( compressionBuffer.size() )
				) ;
				std::copy( &compressionBuffer[0], &compressionBuffer[0]+compressionBuffer.size(), outIt ) ;
				progress_context( i+1, bgenView.number_of_variants() ) ;
			}
		}
		
		std::cerr << boost::format( "# %s: success, total %d variants.\n" ) % globals::program_name % bgenView.number_of_variants() ;
	}
	
	std::vector< uint64_t > compute_probability_encoding_table() const {
		// In bgen v1.2 8 bit encoding,
		// Each sample is encoded with 2 bytes.
		// First byte = prob1 * 255
		// Second byte = prob2 * 255
		// Third byte should make these add up to 255.
		std::vector< uint64_t > result( 65536, 0u ) ;
		for( uint16_t x = 0; x <= 255; ++x ) {
			for( uint16_t y = 0; y <= (255-x); ++y ) {
				uint16_t z = 255-x-y ;
				uint16_t key = (y<<8) | x ;
				// value is 32768.0
				uint64_t a = std::round((double(x)/255.0)*32768.0) ;
				uint64_t b = std::round((double(y)/255.0)*32768.0) ;
				uint64_t c = std::round((double(z)/255.0)*32768.0) ;
				uint64_t value = a | (b << 16) | (c << 32) ;
				result[key] = value ;
				//std::cerr << boost::format( "x=%d, y=%d, z=%d, a=%d, b=%d, c=%d" ) % x % y % z % a % b % c << ": " ;
				//std::cerr << boost::format( "result=%6x\n" ) % value ;
			}
		}
		return result ;
	}
	
	boost::tuple< std::string, uint32_t, uint32_t > parse_range( std::string const& spec ) const {
		std::size_t colon_pos = spec.find( ':' ) ;
		if ( colon_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::vector< std::string > pieces ;
		pieces.push_back( spec.substr( 0, colon_pos )) ;
		pieces.push_back( spec.substr( colon_pos+1, spec.size() )) ;

		if ( pieces.size() != 2 ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::size_t separator_pos = pieces[1].find( '-' ) ;
		if ( separator_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::string chromosome( pieces[0] ) ;
		int pos1 = (separator_pos == 0) ? 0 : std::stoi( pieces[1].substr( 0, separator_pos ) ) ;
		int pos2 = (separator_pos == (pieces[1].size()-1)) ? std::numeric_limits< int >::max() : std::stoi( pieces[1].substr( separator_pos + 1, pieces[1].size() ) ) ;
		assert( pos1 >= 0 ) ;
		assert( pos2 >= pos1 ) ;

		return boost::make_tuple( chromosome, uint32_t( pos1 ), uint32_t( pos2 ) ) ;
	}	
} ;

int main( int argc, char** argv ) {
    try {
		IndexBgenApplication app( argc, argv ) ;
    }
	catch( appcontext::HaltProgramWithReturnCode const& e ) {
		return e.return_code() ;
	}
	return 0 ;
}
