
//          Copyright Gavin Band 2008 - 2012.
// Distributed under the Boost Software License, Version 1.0.
//    (See accompanying file LICENSE_1_0.txt or copy at
//          http://www.boost.org/LICENSE_1_0.txt)

#include <string>
#include <fstream>
#include <vector>
#include <algorithm>
#include <boost/filesystem.hpp>
#include <boost/format.hpp>
#include <boost/tuple/tuple.hpp>
#include "appcontext/CmdLineOptionProcessor.hpp"
#include "appcontext/ApplicationContext.hpp"
#include "appcontext/get_current_time_as_string.hpp"
#include "genfile/bgen/bgen.hpp"
#include "genfile/zlib.hpp"
#include "db/Connection.hpp"
#include "db/SQLStatement.hpp"
#include "../../bgen_revision_autogenerated.hpp"

namespace bfs = boost::filesystem ;

// #define DEBUG 1

namespace globals {
	std::string const program_name = "bgenix" ;
	std::string const program_version = bgen_revision ;
}

struct IndexBgenOptionProcessor: public appcontext::CmdLineOptionProcessor
{
public:
	std::string get_program_name() const { return globals::program_name ; }

	void declare_options( appcontext::OptionProcessor& options ) {
		// Meta-options
		options.set_help_option( "-help" ) ;

		options.declare_group( "Input / output file options" ) ;
		options[ "-g" ]
			.set_description(
				"Path of bgen file to operate on.  (An optional form where \"-g\" is omitted and the filename is specified as the first argument, i.e. bgenix <filename>, can also be used)."
			)
			.set_takes_single_value()
			.set_takes_value_by_position(1)
			.set_is_required()
		;

		options[ "-table" ]
			.set_description( "Specify the table (or view) that bgenix should read the file index from."
				"This only affects reading the index file.  The named table or view should have the"
				" same schema as the Variant table written by bgenix on index creation."
			)
			.set_takes_single_value()
			.set_default_value( "Variant" )
		;
		
		options.declare_group( "Indexing options" ) ;
		options[ "-index" ]
			.set_description( "Specify that bgenix should build an index for the BGE file"
				" specified by the -g option."
			)
		;
		options[ "-clobber" ]
			.set_description(
				"Specify that bgenix should overwrite existing index file if it exists."
			)
		;

		options.declare_group( "Variant selection options" ) ;
		options[ "-incl-range" ]
			.set_description(
				"Include variants in the specified genomic interval in the output. "
				"(If the argument is the name of a valid readable file, the file will "
				"be opened and whitespace-separated rsids read from it instead.)"
				" Each interval must be of the form <chr>:<pos1>-<pos2> where <chr> is a chromosome identifier "
				" and pos1 and pos2 are positions with pos2 >= pos1. "
				" One of pos1 and pos2 can also be omitted, in which case the range extends to the start or"
				" end of the chromosome as appropriate. "
				" Position ranges are treated as closed (i.e. <pos1> and <pos2> are included in the range)."
				"If this is specified multiple times, variants in any of the specified ranges will be included."
			)
			.set_takes_value_by_position(2)
			.set_takes_values_until_next_option()
		;

		options[ "-excl-range" ]
			.set_description(
				"Exclude variants in the specified genomic interval from the output. "
				"See the description of -incl-range for details."
				"If this is specified multiple times, variants in any of the specified ranges will be excluded."
			)
			.set_takes_values_until_next_option()
		;

		options[ "-incl-rsids" ]
			.set_description(
				"Include variants with the specified rsid(s) in the output. "
				"If the argument is the name of a valid readable file, the file will "
				"be opened and whitespace-separated rsids read from it instead."
				"If this is specified multiple times, variants with any of the specified ids will be included."
			)
			.set_takes_values_until_next_option()
		;

		options[ "-excl-rsids" ]
			.set_description(
				"Exclude variants with the specified rsid(s) from the output. "
				"See the description of -incl-range for details."
					"If this is specified multiple times, variants with any of the specified ids will be excluded."
			)
			.set_takes_values_until_next_option()
		;
		
		options.declare_group( "Output options" ) ;
		options[ "-list" ]
			.set_description( "Suppress BGEN output; instead output a list of variants." ) ;
		options[ "-v11" ]
			.set_description(
				"Transcode output to BGEN v1.1 format.  Currently, this is only supported if the input"
				" is in v1.2 format with 8 bits per probability, diploid samples and biallelic variants."
			) ;
		options[ "-with-rowid" ]
			.set_description( "Create an index file without using the 'WITHOUT ROWID' tables.  These are suitable for use with sqlite versions < 3.8.2" ) ;

		// Option interdependencies
		options.option_excludes_group( "-index", "Variant selection options" ) ;
		options.option_implies_option( "-clobber", "-index" ) ;
	}
} ;

typedef uint8_t byte_t ;

struct BgenProcessor {
	
	BgenProcessor( std::string const& filename ):
		m_filename( filename ),
		m_state( e_NotOpen )
	{
		m_last_write_time = boost::filesystem::last_write_time( filename ) ;

		// Open the stream
		m_stream.reset(
			new std::ifstream( filename, std::ifstream::binary )
		) ;
		if( !*m_stream ) {
			throw std::invalid_argument( filename ) ;
		}
		
		// get file size
		{
			std::ios::streampos origin = m_stream->tellg() ;
			m_stream->seekg( 0, std::ios::end ) ;
			m_file_size = m_stream->tellg() - origin ;
			m_stream->seekg( 0, std::ios::beg ) ;
			m_first_bytes.resize( 1000, 0 ) ;
			m_stream->read( reinterpret_cast< char* >( &m_first_bytes[0] ), 1000 ) ;
			m_stream->seekg( 0, std::ios::beg ) ;
			m_stream->clear() ;
		}
		
		m_state = e_Open ;

		// Read the offset, header, and sample IDs if present.
		genfile::bgen::read_offset( *m_stream, &m_offset ) ;
		genfile::bgen::read_header_block( *m_stream, &m_context ) ;

		// Skip anything else until the first variant
		m_stream->seekg( m_offset + 4 ) ;

		// We update track of the start and end of each variant
		m_current_variant_position = ( m_offset + 4 ) ;

		// We keep track of state (though it's not really needed for this implementation.)
		m_state = e_ReadyForVariant ;
	}

	genfile::bgen::Context const& context() const {
		return m_context ;
	}

	std::streampos current_position() const {
		return m_current_variant_position ;
	}

	void seek_to( std::streampos pos ) {
		m_current_variant_position = pos ;
		m_stream->seekg( pos ) ;
		m_state = e_ReadyForVariant ;
	}

	int64_t file_size() const {
		return m_file_size ;
	}

	std::time_t last_write_time() const {
		return m_last_write_time ;
	}

	std::vector< byte_t > const& first_1000_bytes() const {
		return m_first_bytes ;
	}
	
	uint32_t number_of_variants() const {
		return m_context.number_of_variants ;
	}

	// Attempt to read identifying information about a variant from the bgen file, returning
	// it in the given fields.
	// If this method returns true, data was successfully read, and it should be safe to call
	// read_probability_data() or ignore_probability_data().
	// If this method returns false, data was not successfully read indicating the end of the file.
	bool read_variant(
		std::string* SNPID,
		std::string* rsid,
		std::string* chromosome,
		uint32_t* position,
		std::vector< std::string >* alleles
	) {
		assert( m_state == e_ReadyForVariant ) ;
		
		if(
			genfile::bgen::read_snp_identifying_data(
				*m_stream, m_context,
				SNPID, rsid, chromosome, position,
				[&alleles]( std::size_t n ) { alleles->resize( n ) ; },
				[&alleles]( std::size_t i, std::string const& allele ) { alleles->at(i) = allele ; }
			)
		) {
			m_state = e_ReadyForProbs ;
			return true ;
		} else {
			return false ;
		}
	}
	
	// Ignore genotype probability data for the SNP just read using read_variant()
	// After calling this method it should be safe to call read_variant()
	// to fetch the next variant from the file.
	void ignore_probability_data() {
		genfile::bgen::ignore_genotype_data_block( *m_stream, m_context ) ;
		m_current_variant_position = m_stream->tellg() ;
		m_state = e_ReadyForVariant ;
	}

	// Read and uncompress genotype probability data, but don't do anything with it.
	std::vector< byte_t > const& read_raw_probability_data() {
		genfile::bgen::read_genotype_data_block( *m_stream, m_context, &m_buffer1 ) ;
		m_current_variant_position = m_stream->tellg() ;
		m_state = e_ReadyForVariant ;
		genfile::bgen::uncompress_probability_data( m_context, m_buffer1, &m_buffer2 ) ;
		return m_buffer2 ;
	}

private:
	std::string const m_filename ;
	std::unique_ptr< std::istream > m_stream ;

	// meta-data we record to avoid using a stale index file
	int64_t m_file_size ;
	std::time_t m_last_write_time ;
	std::vector< byte_t > m_first_bytes ;

	// bgen::Context object holds information from the header block,
	// including bgen flags
	genfile::bgen::Context m_context ;

	// offset byte from top of bgen file.
	uint32_t m_offset ;

	// We keep track of our state in the file.
	// Not strictly necessary for this implentation but makes it clear that
	// calls must be read_variant() followed by ignore_probability_data() or ignore_probability_data()
	// repeatedly.
	enum State { e_NotOpen = 0, e_Open = 1, e_ReadyForVariant = 2, e_ReadyForProbs = 3, eComplete = 4 } ;
	State m_state ;
	
	// To avoid issues with tellg() and failbit, we store the stream position at suitable points
	std::streampos m_current_variant_position ;
	
	// Two buffers for processing
	std::vector< byte_t > m_buffer1 ;
	std::vector< byte_t > m_buffer2 ;
} ;

struct IndexBgenApplication: public appcontext::ApplicationContext
{
public:
	IndexBgenApplication( int argc, char** argv ):
		appcontext::ApplicationContext(
			globals::program_name,
			globals::program_version,
			std::auto_ptr< appcontext::OptionProcessor >( new IndexBgenOptionProcessor ),
			argc,
			argv,
			"-log"
		)
	{
		setup() ;
	}

private:
	std::string m_bgen_filename ;
	std::string m_index_filename ;

private:
	void setup() {
		m_bgen_filename = options().get< std::string >( "-g" ) ;
		m_index_filename = m_bgen_filename + ".bgi" ;
		if( !bfs::exists( m_bgen_filename )) {
			throw std::invalid_argument( m_bgen_filename ) ;
		}
		if( options().check( "-index" )) {
			if( bfs::exists( m_index_filename ) && !options().check( "-clobber" )) {
				std::cerr << "Index file \"" + m_index_filename + "\" already exists, use -clobber if you want to overwrite it.\n" ;
				throw appcontext::HaltProgramWithReturnCode( -1 ) ;
			} else {
				create_bgen_index( m_bgen_filename, m_index_filename ) ;
			}
		} else {
			process_selection( m_bgen_filename, m_index_filename ) ;
		}
	}

	void create_bgen_index( std::string const& bgen_filename, std::string const& index_filename ) {
		db::Connection::UniquePtr result ;
		ui().logger()
			<< boost::format( "%s: creating index for \"%s\" in \"%s\"...\n" ) % globals::program_name % bgen_filename % index_filename ;

		try {
			if( bfs::exists( index_filename + ".tmp" ) && !options().check( "-clobber" ) ) {
				ui().logger() << "!! Error, an incomplete index file \"" + (index_filename + ".tmp") + "\" exists.\n"
					"This probably reflects a bgenix job that was terminated.\n"
					"Use -clobber to overwrite (or delete the file).\n" ;
				throw std::invalid_argument( index_filename ) ;
			}
			result = create_bgen_index_unsafe( bgen_filename, index_filename + ".tmp" ) ;
			bfs::rename( index_filename + ".tmp", index_filename ) ;
		} catch( db::StatementStepError const& e ) {
			ui().logger() << "!! Error in \"" << e.spec() << "\": " << e.description() << ".\n" ;
			bfs::remove( index_filename + ".tmp" ) ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		} catch( ... ) {
			// Remove the incomplete attempt at an index file.
			bfs::remove( index_filename + ".tmp" ) ;
			throw ;
		}
	}
	
	db::Connection::UniquePtr create_bgen_index_unsafe( std::string const& bgen_filename, std::string const& index_filename ) {
		db::Connection::UniquePtr connection = db::Connection::create( index_filename, "rw" ) ;

		connection->run_statement( "PRAGMA locking_mode = EXCLUSIVE ;" ) ;
		connection->run_statement( "PRAGMA journal_mode = MEMORY ;" ) ;
		
		db::Connection::ScopedTransactionPtr transaction = connection->open_transaction( 240 ) ;
		setup_index_file( *connection ) ;
		// Close and open the transaction
		transaction.reset() ;

		db::Connection::StatementPtr insert_metadata_stmt = connection->get_statement(
			"INSERT INTO Metadata( filename, file_size, last_write_time, first_1000_bytes, index_creation_time ) VALUES( ?, ?, ?, ?, ? )"
		) ;

		db::Connection::StatementPtr insert_variant_stmt = connection->get_statement(
			"INSERT INTO Variant( chromosome, position, rsid, number_of_alleles, allele1, allele2, file_start_position, size_in_bytes ) "
			"VALUES( ?, ?, ?, ?, ?, ?, ?, ? )"
		) ;

		BgenProcessor processor( bgen_filename ) ;

		insert_metadata_stmt
			->bind( 1, bgen_filename )
			.bind( 2, processor.file_size() )
			.bind( 3, uint64_t( processor.last_write_time() ) )
			.bind( 4, &processor.first_1000_bytes()[0], &processor.first_1000_bytes()[0] + processor.first_1000_bytes().size() )
			.bind( 5, appcontext::get_current_time_as_string() )
			.step() ;

		ui().logger()
			<< boost::format( "%s: Opened \"%s\" with %d variants...\n" ) % globals::program_name % bgen_filename % processor.number_of_variants() ;
		
		std::string chromosome, rsid, SNPID ;
		uint32_t position ;
		std::vector< std::string > alleles ;
		alleles.reserve(100) ;
		std::size_t const chunk_size = 10 ;
		
		transaction = connection->open_transaction( 240 ) ;
		
		{
			auto progress_context = ui().get_progress_context( "Building BGEN index" ) ;
			std::size_t variant_count = 0;
			int64_t file_pos = int64_t( processor.current_position() ) ;
			try {
				while( processor.read_variant( &SNPID, &rsid, &chromosome, &position, &alleles ) ) {
#if DEBUG
					std::cerr << "read variant:" << chromosome << " " << position << " " << rsid << " " << file_pos << " " << alleles.size() << ".\n" << std::flush ;
					std::cerr << "alleles: " << alleles[0] << ", "  << alleles[1] << ".\n" << std::flush ;
#endif
					processor.ignore_probability_data() ;
					int64_t file_end_pos = int64_t( processor.current_position() ) ;
					assert( alleles.size() > 1 ) ;
					assert( (file_end_pos - file_pos) > 0 ) ;
					insert_variant_stmt
						->bind( 1, chromosome )
						.bind( 2, position )
						.bind( 3, rsid )
						.bind( 4, int64_t( alleles.size() ) )
						.bind( 5, alleles[0] )
						.bind( 6, alleles[1] )
						.bind( 7, file_pos )
						.bind( 8, file_end_pos - file_pos )
						.step()
					;
					insert_variant_stmt->reset() ;
				
					progress_context( ++variant_count, processor.number_of_variants() ) ;
			
				// Make sure and commit every 10000 SNPs.
					if( variant_count % chunk_size == 0 ) {
		//				ui().logger()
		//					<< boost::format( "%s: Writing variants %d-%d...\n" ) % processor.number_of_variants() % (variant_count-chunk_size) % (variant_count-1) ;
					
						transaction.reset() ;
						transaction = connection->open_transaction( 240 ) ;
					}
					file_pos = file_end_pos ;
#if DEBUG
					std::cerr << "Record inserted.\n" << std::flush ;
#endif
								}
			}
			catch( genfile::bgen::BGenError const& e ) {
				ui().logger() << "!! (" << e.what() << "): an error occurred reading from the input file.\n" ;
				ui().logger() << "Last observed variant was \"" << SNPID.substr(0,10) << "\", \"" << rsid.substr(0,10) << "\"...\n" ;
				ui().logger() << "Reached byte " << file_pos << " in input file, which has size " << processor.file_size() << ".\n" ;
				throw ;
			}
 			catch( db::StatementStepError const& e ) {
				ui().logger() << "Last observed variant was " << SNPID << " " << rsid << " " << chromosome << " " << position ;
				for( std::size_t i = 0; i < alleles.size(); ++i ) {
					ui().logger() << " " << alleles[i] ;
				}
				ui().logger() << "\n" ;
				ui().logger() << "Reached byte " << file_pos << " in input file, which has size " << processor.file_size() << ".\n" ;
				throw ;
			}
		}
		return connection ;
	}
	
	void setup_index_file( db::Connection& connection ) {
		std::string const tag = options().check( "-with-rowid" ) ? "" : " WITHOUT ROWID" ;

		connection.run_statement(
			"CREATE TABLE Metadata ("
			" filename TEXT NOT NULL,"
			" file_size INT NOT NULL,"
			" last_write_time INT NOT NULL,"
			" first_1000_bytes BLOB NOT NULL,"
			" index_creation_time INT NOT NULL"
			")"
		) ;

		connection.run_statement(
			"CREATE TABLE Variant ("
			"  chromosome TEXT NOT NULL,"
			"  position INT NOT NULL,"
			"  rsid TEXT NOT NULL,"
			"  number_of_alleles INT NOT NULL,"
			"  allele1 TEXT NOT NULL,"
			"  allele2 TEXT NULL,"
			"  file_start_position INT NOT NULL," // 
			"  size_in_bytes INT NOT NULL,"       // We put these first to minimise cost of retrieval
			"  PRIMARY KEY (chromosome, position, rsid, allele1, allele2, file_start_position )"
			")" + tag
		) ;
	}
	
	void process_selection( std::string const& bgen_filename, std::string const& index_filename ) const {
		try {
			process_selection_unsafe( bgen_filename, index_filename ) ;
		}
		catch( ... ) {
			throw ;
		}
	}

	void process_selection_unsafe( std::string const& bgen_filename, std::string const& index_filename ) const {
		db::Connection::UniquePtr connection ;
		try {
			connection = db::Connection::create( index_filename, "r" ) ;
			verify_metadata( *connection, bgen_filename ) ;
		} catch( db::ConnectionError const& e ) {
			std::cerr << "!! Unable to open index file \"" + index_filename + "\" (run bgenix -index first).\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
		std::string const& select_sql = get_select_sql( *connection ) ;
#if DEBUG
		std::cerr << "Running sql: \"" << select_sql << "\"...\n" ;
#endif
		std::vector< std::pair< int64_t, int64_t> > positions ;
		{
			auto progress_context = ui().get_progress_context( "Selecting variants" ) ;
			progress_context( 0, boost::optional< std::size_t >() ) ;
			db::Connection::StatementPtr stmt = connection->get_statement( select_sql ) ;
			{
				positions.reserve( 1000000 ) ;
				std::size_t batch_i = 0 ;
				for( stmt->step() ; !stmt->empty(); stmt->step(), ++batch_i ) {
					int64_t const pos = stmt->get< int64_t >( 0 ) ;
					int64_t const size = stmt->get< int64_t >( 1 ) ;
					assert( pos >= 0 ) ;
					assert( size >= 0 ) ;
					positions.push_back( std::make_pair( int64_t( pos ), int64_t( size ))) ;
					progress_context( positions.size(), boost::optional< std::size_t >() ) ;
				}
			}
		}

		if( options().check( "-list" ) ) {
			process_selection_list( bgen_filename, positions ) ;
		} else if( options().check( "-v11" )) {
			// peek at the file.  If already v1.1 we can do it without transcoding.
			BgenProcessor processor( bgen_filename ) ;
			uint32_t const bgen_v11_flags = (genfile::bgen::e_Layout1 | genfile::bgen::e_ZlibCompression) ;
#if DEBUG
			std::cerr << boost::format( "flags = %x\n" ) % processor.context().flags ;
#endif
			if( processor.context().flags == bgen_v11_flags ) {
				ui().logger() << "++ Option -v11 specified, but input format is already BGEN v1.1.\n"
					<< "++ I will copy blocks to output instead of transcoding.\n" ;
				process_selection_notranscode(
					bgen_filename,
					positions
				) ;
			} else {
				process_selection_transcode( bgen_filename, positions, "bgen_v1.1" ) ;
			}
		} else {
			process_selection_notranscode( bgen_filename, positions ) ;
		}
	}

	void verify_metadata( db::Connection& connection, std::string const& bgen_filename ) const {
		{
			// Find and verify the metadata
			db::Connection::StatementPtr stmt = connection.get_statement( "SELECT * FROM sqlite_master WHERE name == 'Metadata' AND type == 'table'" ) ;
			stmt->step() ;
			
			if( !stmt->empty() ) {
				db::Connection::StatementPtr mdStmt = connection.get_statement( "SELECT file_size, last_write_time, first_1000_bytes FROM Metadata" ) ;
				mdStmt->step() ;
				if( !mdStmt->empty() ) {
					int64_t md_fileSize = mdStmt->get< int64_t >( 0 ) ;
//					int64_t md_lastWriteTime = mdStmt->get< int64_t >( 1 ) ;
					std::vector< uint8_t > md_first_1000_bytes = mdStmt->get< std::vector< uint8_t > >( 2 ) ;
					std::vector< uint8_t > m_first_1000_bytes( 1000, 0 ) ;

					// Verify bgen file against metadata
//					int64_t const lastWriteTime = boost::filesystem::last_write_time( bgen_filename ) ;
					std::ifstream bgen( bgen_filename.c_str() ) ;
					std::ios::streampos origin = bgen.tellg() ;
					bgen.read( reinterpret_cast< char* >( &m_first_1000_bytes[0] ), 1000 ) ;
					bgen.clear() ;
					bgen.seekg( 0, std::ios::end ) ;
					std::ios::streamoff const fileSize = bgen.tellg() - origin ;
					if( md_fileSize != fileSize ) {
						std::cerr << "!! Size of file (\"" << bgen_filename << "\" ("
							<< fileSize << " bytes)"
							<< "differs from that recorded in the index file (" << md_fileSize << ").\n"
							<< "Do you need to recreate the index?\n" ;
						throw appcontext::HaltProgramWithReturnCode( -1 ) ;
					}
					if( m_first_1000_bytes != md_first_1000_bytes ) {
						std::cerr << "!! File (\"" << bgen_filename << "\" has different initial bytes"
							" than recorded in the index file - that can't be right.\n"
							<< "Do you need to recreate the index?\n" ;
						throw appcontext::HaltProgramWithReturnCode( -1 ) ;
					}
				}
			}
		}
	}

	void process_selection_notranscode( std::string const& bgen_filename, std::vector< std::pair< int64_t, int64_t> > const& positions ) const {
		std::ifstream bgen_file( bgen_filename, std::ios::binary ) ;
		uint32_t offset = 0 ;

		using namespace genfile ;
		bgen::Context context ;
		bgen::read_offset( bgen_file, &offset ) ;
		bgen::read_header_block( bgen_file, &context ) ;

		// Write the new context after adjusting the variant count.
		context.number_of_variants = positions.size() ;
		bgen::write_offset( std::cout, offset ) ;
		bgen::write_header_block( std::cout, context ) ;
		std::istreambuf_iterator< char > inIt( bgen_file ) ;
		std::istreambuf_iterator< char > endInIt ;
		std::ostreambuf_iterator< char > outIt( std::cout ) ;

		// Copy everything else up to the start of the data
		std::copy_n( inIt, offset - context.header_size(), outIt ) ;

		{
			auto progress_context = ui().get_progress_context( "Processing " + std::to_string( positions.size() ) + " variants" ) ;
			// Now we go for it
			for( std::size_t i = 0; i < positions.size(); ++i ) {
				bgen_file.seekg( positions[i].first ) ;
				std::istreambuf_iterator< char > inIt( bgen_file ) ;
				std::copy_n( inIt, positions[i].second, outIt ) ;
				progress_context( i+1, positions.size() ) ;
			}
		}
		std::cerr << boost::format( "%s: wrote data for %d variants to stdout.\n" ) % globals::program_name % positions.size() ;
	}
	
	void process_selection_list( std::string const& bgen_filename, std::vector< std::pair< int64_t, int64_t> > const& positions ) const {
		BgenProcessor processor( bgen_filename ) ;
		std::cout << boost::format( "# %s: started %s\n" ) % globals::program_name % appcontext::get_current_time_as_string() ;
		std::cout << "alternate_ids\trsid\tchromosome\tposition\tnumber_of_alleles\tfirst_allele\talternative_alleles\n" ;
		
		std::string SNPID, rsid, chromosome ;
		uint32_t position ;
		std::vector< std::string > alleles ;

		for( std::size_t i = 0; i < positions.size(); ++i ) {
			processor.seek_to( positions[i].first ) ;
			bool success = processor.read_variant(
				&SNPID, &rsid, &chromosome, &position, &alleles
			) ;
			if( SNPID.empty() ) {
				SNPID = "." ;
			}
			if( rsid.empty() ) {
				rsid = "." ;
			}
			std::cout << SNPID << "\t" << rsid << "\t" << chromosome << "\t" << position << "\t" << alleles.size() << "\t" << alleles[0] << "\t" ;
			for( std::size_t allele_i = 1; allele_i < alleles.size(); ++allele_i ) {
				std::cout << (( allele_i > 1 ) ? "," : "" ) << alleles[allele_i] ;
			}
			std::cout << "\n" ;
			if( !success ) {
				throw std::invalid_argument( "positions" ) ;
			}
			processor.ignore_probability_data() ;
		}
		
		std::cout << boost::format( "# %s: success, total %d variants.\n" ) % globals::program_name % positions.size() ;
	}

	void process_selection_transcode(
		std::string const& bgen_filename,
		std::vector< std::pair< int64_t, int64_t> > const& positions,
		std::string const& format
	) const {
		if( format != "bgen_v1.1" ) {
			std::cerr << "!! Only -transcode bgen_v1.1 is currently supported.\n" ;
			throw std::invalid_argument( "format=\"" + format + "\"" ) ;
		}
		process_selection_transcode_bgen_v11(
			bgen_filename,
			positions
		) ;
	}

	void process_selection_transcode_bgen_v11(
		std::string const& bgen_filename,
		std::vector< std::pair< int64_t, int64_t> > const& positions
	) const {
		BgenProcessor processor( bgen_filename ) ;

		// Currently this is only supported in a very restricted scenario.
		// Namely, when the format is BGEN v1.2, unphased data, encoded
		// with 8 bits per probability, converting to a BGEN v1.1 file.
		// And all variants must be biallelic.
		uint32_t const inputLayout = processor.context().flags & genfile::bgen::e_Layout ;
		if( inputLayout != genfile::bgen::e_Layout2 ) {
			throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
		}

		// specify flags for BGEN v1.1
		// This means layout 1, no sample identifiers, zlib compression.
		genfile::bgen::Context outputContext = processor.context() ;
		outputContext.flags = genfile::bgen::e_Layout1 | genfile::bgen::e_ZlibCompression ;
		outputContext.number_of_variants = positions.size() ;
		
		// Write offset and header
		genfile::bgen::write_offset( std::cout, outputContext.header_size() ) ;
		genfile::bgen::write_header_block( std::cout, outputContext ) ;

		// We require two buffers: one to serialise data to,
		// and one to assemble final compressed result to.
		std::vector< byte_t > serialisationBuffer( 6 * outputContext.number_of_samples ) ;
		std::vector< byte_t > idDataBuffer ;
		std::vector< byte_t > compressionBuffer ;

		std::string SNPID, rsid, chromosome ;
		uint32_t position ;
		std::vector< std::string > alleles ;

		std::vector< uint64_t > probability_encoding_table = compute_probability_encoding_table() ;

		for( std::size_t i = 0; i < positions.size(); ++i ) {
			processor.seek_to( positions[i].first ) ;
			bool success = processor.read_variant(
				&SNPID, &rsid, &chromosome, &position, &alleles
			) ;
			
			if( alleles.size() != 2 ) {
				std::cerr
					<< "In -transcode, found variant with " << alleles.size() << " allele, only 2 alleles are supported by BGEN v1.1.\n" ;
				throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			
			genfile::bgen::write_snp_identifying_data(
				&idDataBuffer,
				outputContext,
				SNPID, rsid, chromosome, position,
				uint16_t( 2 ), 
				[&alleles](std::size_t i) { return alleles[i] ; }
			) ;
			
			std::vector< byte_t > const& data = processor.read_raw_probability_data() ;

			// This is as in bgen::v12::impl::parse_probability_data()
			// TODO: can I abstract this out?
			byte_t const* buffer = &data[0] ;
			byte_t const* end = &data[0] + data.size() ;

			uint32_t numberOfSamples ;
			uint16_t numberOfAlleles ;
			byte_t ploidyExtent[2] ;
			enum { ePhased = 1, eUnphased = 0 } ;
			
			if( end < buffer + 8 ) {
				throw std::domain_error( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			buffer = genfile::bgen::read_little_endian_integer( buffer, end, &numberOfSamples ) ;
			buffer = genfile::bgen::read_little_endian_integer( buffer, end, &numberOfAlleles ) ;
			buffer = genfile::bgen::read_little_endian_integer( buffer, end, &ploidyExtent[0] ) ;
			buffer = genfile::bgen::read_little_endian_integer( buffer, end, &ploidyExtent[1] ) ;
			// Keep a pointer to the ploidy and move buffer past the ploidy information
			byte_t const* ploidy_p = buffer ;
			buffer += numberOfSamples ;
			// Get the phased flag and number of bits
			bool const phased = ((*buffer++) & 0x1 ) ;
			int const bits = int( *reinterpret_cast< byte_t const *>( buffer++ ) ) ;

			if( numberOfSamples != processor.context().number_of_samples ) {
				std::cerr
					<< "In -transcode, # samples for row (" << numberOfSamples
					<< ") does not match number in header (" << processor.context().number_of_samples
					<< ").\n" ;
				throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			if( bits != 8 ) {
				std::cerr << "For -v11, expected 8 bits per probability, found " << bits << ".\n" ;
				throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			if( phased != 0 ) {
				std::cerr << "For -v11, expected unphased data.\n" ;
				throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			if( end < buffer + numberOfSamples + 2 ) {
				throw std::invalid_argument( "bgen_filename=\"" + bgen_filename + "\"" ) ;
			}
			byte_t* out_p = &serialisationBuffer[0] ;
			byte_t const* p = ploidy_p ;
			for( ; p < (ploidy_p + numberOfSamples); ++p, buffer += 2 ) {
				if( *p & byte_t( 0x80 ) ) {
					// data is missing, encode as zeros.
					*out_p++ = 0 ; *out_p++ = 0 ;
					*out_p++ = 0 ; *out_p++ = 0 ;
					*out_p++ = 0 ; *out_p++ = 0 ;
				} else {
					std::size_t const key = *reinterpret_cast< uint16_t const* >( buffer ) ;
					assert( key < probability_encoding_table.size() ) ;
					uint64_t const value = probability_encoding_table[ *reinterpret_cast< uint16_t const* >( buffer ) ] ;
#if DEBUG
					std::cerr << ( boost::format( "%d, %d" ) % key % probability_encoding_table.size() ) << "\n" ;
					std::cerr << ( boost::format( "%x: %x" ) % key % value ) << "\n" ;
					std::cerr << "Input: " << uint64_t(*reinterpret_cast< uint8_t const* >( buffer )) << ", " << uint64_t(*reinterpret_cast< uint8_t const* >( buffer+1 )) << "\n" ;
					std::cerr << "Output: " << uint64_t( value & 0xFFFF) << ", " << uint64_t( (value>>16) & 0xFFFF) << ", " << uint64_t( (value>>32) & 0xFFFF) << ".\n" ;
#endif
					*out_p++ = ( (value >> 0) & 0xFF ) ;
					*out_p++ = ( (value >> 8) & 0xFF ) ;
					*out_p++ = ( (value >> 16) & 0xFF ) ;
					*out_p++ = ( (value >> 24) & 0xFF ) ;
					*out_p++ = ( (value >> 32) & 0xFF ) ;
					*out_p++ = ( (value >> 40) & 0xFF ) ;
				}
			}
			
			// Compress it.
			assert( out_p == &serialisationBuffer[0] + serialisationBuffer.size() ) ;
			genfile::zlib_compress(
				serialisationBuffer,
				&compressionBuffer,
				1 // compression level
			) ;
#if DEBUG
			std::cerr << ( boost::format( "serialisation buffer: %d, id data Buffer: %d, result buffer: %d" ) % serialisationBuffer.size() % idDataBuffer.size() % compressionBuffer.size() ) << "\n" ;
#endif
			std::ostreambuf_iterator< char > outIt( std::cout ) ;
			std::copy( &idDataBuffer[0], &idDataBuffer[0]+idDataBuffer.size(), outIt ) ;
			genfile::bgen::write_little_endian_integer(
				std::cout,
				uint32_t( compressionBuffer.size() )
			) ;
			std::copy( &compressionBuffer[0], &compressionBuffer[0]+compressionBuffer.size(), outIt ) ;
		}
		
		std::cerr << boost::format( "# %s: success, total %d variants.\n" ) % globals::program_name % positions.size() ;
	}
	
	std::vector< uint64_t > compute_probability_encoding_table() const {
		// In bgen v1.2 8 bit encoding,
		// Each sample is encoded with 2 bytes.
		// First byte = prob1 * 255
		// Second byte = prob2 * 255
		// Third byte should make these add up to 255.
		std::vector< uint64_t > result( 65536, 0u ) ;
		for( uint16_t x = 0; x <= 255; ++x ) {
			for( uint16_t y = 0; y <= (255-x); ++y ) {
				uint16_t z = 255-x-y ;
				uint16_t key = (y<<8) | x ;
				// value is 32768.0
				uint64_t a = std::round((double(x)/255.0)*32768.0) ;
				uint64_t b = std::round((double(y)/255.0)*32768.0) ;
				uint64_t c = std::round((double(z)/255.0)*32768.0) ;
				uint64_t value = a | (b << 16) | (c << 32) ;
				result[key] = value ;
				//std::cerr << boost::format( "x=%d, y=%d, z=%d, a=%d, b=%d, c=%d" ) % x % y % z % a % b % c << ": " ;
				//std::cerr << boost::format( "result=%6x\n" ) % value ;
			}
		}
		return result ;
	}
	
	boost::tuple< std::string, uint32_t, uint32_t > parse_range( std::string const& spec ) const {
		std::size_t colon_pos = spec.find( ':' ) ;
		if ( colon_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::vector< std::string > pieces ;
		pieces.push_back( spec.substr( 0, colon_pos )) ;
		pieces.push_back( spec.substr( colon_pos+1, spec.size() )) ;

		if ( pieces.size() != 2 ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::size_t separator_pos = pieces[1].find( '-' ) ;
		if ( separator_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::string chromosome( pieces[0] ) ;
		int pos1 = (separator_pos == 0) ? 0 : std::stoi( pieces[1].substr( 0, separator_pos ) ) ;
		int pos2 = (separator_pos == (pieces[1].size()-1)) ? std::numeric_limits< int >::max() : std::stoi( pieces[1].substr( separator_pos + 1, pieces[1].size() ) ) ;
		assert( pos1 >= 0 ) ;
		assert( pos2 >= pos1 ) ;

		return boost::make_tuple( chromosome, uint32_t( pos1 ), uint32_t( pos2 ) ) ;
	}

	std::string get_select_sql( db::Connection& connection ) const {
		std::string result = "SELECT file_start_position, size_in_bytes FROM `"
			+ options().get_value("-table")
			+ "` V" ;
		std::string join ;
		std::string inclusion = "" ;
		std::string exclusion = "" ;
		if( options().check( "-incl-range" )) {
			auto const elts = collect_unique_ids( options().get_values< std::string >( "-incl-range" ));
			//auto elts = options().get_values< std::string >( "-incl-range" ) ;
			for( std::string const& elt: elts ) {
				boost::tuple< std::string, uint32_t, uint32_t > range = parse_range( elt ) ;
				inclusion += ((inclusion.size() > 0) ? " OR " : "" ) + (
					boost::format( "( chromosome == '%s' AND position BETWEEN %d AND %d )" ) % range.get<0>() % range.get<1>() % range.get<2>()
				).str() ;
			}
		}
		if( options().check( "-excl-range" )) {
			auto const elts = collect_unique_ids( options().get_values< std::string >( "-excl-range" ));
			for( std::string const& elt: elts ) {
				boost::tuple< std::string, uint32_t, uint32_t > range = parse_range( elt ) ;
				exclusion += ( exclusion.size() > 0 ? " AND" : "" ) + (
					boost::format( " NOT ( chromosome == '%s' AND position BETWEEN %d AND %d )" ) % range.get<0>() % range.get<1>() % range.get<2>()
				).str() ;
			}
		}
		if( options().check( "-incl-rsids" )) {
			auto const ids = collect_unique_ids( options().get_values< std::string >( "-incl-rsids" ));
			connection.run_statement( "CREATE TEMP TABLE tmpIncludedId( identifier TEXT NOT NULL PRIMARY KEY ) WITHOUT ROWID" ) ;
			db::Connection::StatementPtr insert_stmt = connection.get_statement( "INSERT INTO tmpIncludedId( identifier ) VALUES( ? )" ) ;
			for( auto elt: ids ) {
				insert_stmt
					->bind( 1, elt )
					.step() ;
				insert_stmt->reset() ;
			}
			join += " LEFT OUTER JOIN tmpIncludedId TI ON TI.identifier == V.rsid" ;
			inclusion += ( inclusion.size() > 0 ? " OR" : "" ) + std::string( " TI.identifier IS NOT NULL" ) ;
		}
		if( options().check( "-excl-rsids" )) {
			auto const ids = collect_unique_ids( options().get_values< std::string >( "-excl-rsids" ));
			connection.run_statement( "CREATE TEMP TABLE tmpExcludedId( identifier TEXT NOT NULL PRIMARY KEY ) WITHOUT ROWID" ) ;
			db::Connection::StatementPtr insert_stmt = connection.get_statement( "INSERT INTO tmpExcludedId( identifier ) VALUES( ? )" ) ;
			for( auto elt: ids ) {
				insert_stmt
					->bind( 1, elt )
					.step() ;
				insert_stmt->reset() ;
			}
			join += " LEFT OUTER JOIN tmpExcludedId TE ON TE.identifier == V.rsid" ;
			exclusion += ( exclusion.size() > 0 ? " AND" : "" ) + std::string( " TE.identifier IS NULL" ) ;
		}
		inclusion = ( inclusion.size() > 0 ) ? ("(" + inclusion + ")") : "" ;
		exclusion = ((inclusion.size() > 0 && exclusion.size() > 0 ) ? "AND " : "" ) + (( exclusion.size() > 0 ) ? ("(" + exclusion + ")") : "" ) ;
		std::string const where = (inclusion.size() > 0 || exclusion.size() > 0) ? ("WHERE " + inclusion + exclusion) : "" ;
		std::string const orderBy = "ORDER BY chromosome, position, rsid, allele1, allele2" ;
		return result + " " + join + " " + where + " " + orderBy ;
	}
	
	std::vector< std::string > collect_unique_ids( std::vector< std::string > const& ids_or_filenames ) const {
		std::vector< std::string > result ;
		for( auto elt: ids_or_filenames ) {
			if( bfs::exists( elt )) {
				std::ifstream f( elt ) ;
				std::copy(
					std::istream_iterator< std::string >( f ),
					std::istream_iterator< std::string >(),
					std::back_inserter< std::vector< std::string > >( result )
				) ;
			} else {
				result.push_back( elt ) ;
			}
		}
		// now sort and uniqueify them...
		std::sort( result.begin(), result.end() ) ;
		std::vector< std::string >::const_iterator newBack = std::unique( result.begin(), result.end() ) ;
		result.resize( newBack - result.begin() ) ;
		return result ;
	}

	
} ;

int main( int argc, char** argv ) {
    try {
		IndexBgenApplication app( argc, argv ) ;
    }
	catch( appcontext::HaltProgramWithReturnCode const& e ) {
		return e.return_code() ;
	}
	return 0 ;
}
